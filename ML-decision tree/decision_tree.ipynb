{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the creation of decision tree and accuracy computation on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Paths: \n",
    "- training data: data/mush_train.data\n",
    "- test data: data/mush_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_attribute_index: 4\n",
      "max info gain: 0.8593408948415395\n",
      "best_attribute_index: 19\n",
      "max info gain: 0.028289904575436464\n",
      "best_attribute_index: 21\n",
      "max info gain: 0.5042359749194675\n",
      "best_attribute_index: 20\n",
      "max info gain: 0.7219280948873623\n",
      "\n",
      "Decision tree:\n",
      " 4\n",
      "   e\n",
      "   p\n",
      "   p\n",
      "   e\n",
      "   19\n",
      "     e\n",
      "     e\n",
      "     e\n",
      "     p\n",
      "     21\n",
      "       p\n",
      "       20\n",
      "         p\n",
      "         e\n",
      "       e\n",
      "   p\n",
      "   p\n",
      "   p\n",
      "\n",
      "accuracy: 84.0937114673243 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Tree Node Class\n",
    "class TreeNode(): \n",
    "    def __init__(self, attribute_index, value_path, children, info_gain, class_value): \n",
    "\n",
    "        #decision node\n",
    "        self.attribute_index = attribute_index\n",
    "        self.value_path = value_path #all nodes except root\n",
    "        self.children = children\n",
    "        self.info_gain = info_gain\n",
    "\n",
    "        #leaf node\n",
    "        self.class_value = class_value\n",
    "\n",
    "#Decision Tree Class\n",
    "class DecisionTree(): \n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "\n",
    "    #check if label set is pure\n",
    "    def is_pure(self, label): \n",
    "        classes = np.unique(label)\n",
    "        if len(classes) == 1: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    #classify label\n",
    "    def classify(self, label):\n",
    "        classes, class_count = np.unique(label, return_counts=True)\n",
    "        best_class = classes[class_count.argmax()]\n",
    "        return best_class\n",
    "\n",
    "    #split dataset by attribute value\n",
    "    def split(self, dataset, label, best_attribute_index, value):\n",
    "        #indices of rows for values[j]\n",
    "        split_indices = np.where(dataset[:,best_attribute_index] == value)[0]\n",
    "        split_dataset = dataset[split_indices]\n",
    "        split_label = label[split_indices]\n",
    "        return split_dataset, split_label\n",
    "\n",
    "    #compute entropy\n",
    "    def calculate_entropy(self, label): \n",
    "        classes, class_count = np.unique(label, return_counts=True)\n",
    "        total_count = np.sum(class_count)\n",
    "\n",
    "        entropy_value = 0\n",
    "        for i in range(len(classes)): \n",
    "            proportion = class_count[i] / total_count\n",
    "            entropy_value += (-proportion) * np.log2(proportion)\n",
    "        \n",
    "        return entropy_value\n",
    "\n",
    "    #compute conditional entropy\n",
    "    def calculate_conditional_entropy(self, attribute_set, label):\n",
    "        values, value_count = np.unique(attribute_set, return_counts=True)\n",
    "        \n",
    "        total_count = np.sum(value_count)\n",
    "\n",
    "        conditional_entropy_value = 0\n",
    "        #iterate through each value of the attribute\n",
    "        for i in range(len(values)): \n",
    "            condition_set = np.array([label[y] for y in np.where(attribute_set == values[i])])\n",
    "            conditional_entropy_value += (value_count[i] / total_count) * self.calculate_entropy(condition_set)\n",
    "\n",
    "        return conditional_entropy_value\n",
    "\n",
    "    #create decision tree \n",
    "    def create_decision_tree(self, dataset, label, value, counter):\n",
    "        #base case\n",
    "        if self.is_pure(label): \n",
    "            class_value = self.classify(label)\n",
    "            return TreeNode(None, value, None, None, class_value)\n",
    "        \n",
    "        #recursive step\n",
    "        max_info_gain = 0\n",
    "        best_attribute_index = 0\n",
    "\n",
    "        current_entropy = self.calculate_entropy(label)\n",
    "\n",
    "        #iterate through all attributes to find the one with most information gain \n",
    "        for i in range(dataset.shape[1]):\n",
    "            attribute_set = dataset[:, i]\n",
    "            \n",
    "            conditional_entropy = self.calculate_conditional_entropy(attribute_set, label)\n",
    "            info_gain = current_entropy - conditional_entropy\n",
    "            \n",
    "            if info_gain >= max_info_gain: \n",
    "                max_info_gain = info_gain\n",
    "                best_attribute_index = i\n",
    "        \n",
    "        print(\"best_attribute_index:\", best_attribute_index)\n",
    "        print(\"max info gain:\", max_info_gain)\n",
    "\n",
    "        #terminating criteria\n",
    "        if max_info_gain == 0: \n",
    "            class_value = self.classify(label)\n",
    "            return TreeNode(None, value, None, None, class_value)\n",
    "\n",
    "        #create new TreeNode\n",
    "        current_node = None\n",
    "        #for first node \n",
    "        if counter == 0:\n",
    "            self.root = TreeNode(best_attribute_index, value, [], max_info_gain, None)\n",
    "            current_node = self.root\n",
    "        else: \n",
    "            current_node = TreeNode(best_attribute_index, value, [], max_info_gain, None)\n",
    "            \n",
    "        counter += 1\n",
    "\n",
    "        #split set by each attribute value\n",
    "        values, value_count = np.unique(dataset[:, best_attribute_index], return_counts=True)\n",
    "        #iterate through all attribute values\n",
    "        for j in range(len(values)):\n",
    "            #split data\n",
    "            split_dataset, split_label = self.split(dataset, label, best_attribute_index, values[j])\n",
    "\n",
    "            #compute children on current node recursively\n",
    "            if len(split_label) != 0:\n",
    "                treeNode = self.create_decision_tree(split_dataset, split_label, values[j], counter)\n",
    "                current_node.children.append(treeNode)\n",
    "\n",
    "        return current_node\n",
    "\n",
    "\n",
    "#read file and store data\n",
    "def read_data(filename): \n",
    "    file = open(filename, 'r', encoding='utf-8-sig')\n",
    "    dataset = []\n",
    "    for line in file:\n",
    "        data = line.strip().split(',')\n",
    "        y_data = data[0]\n",
    "        x_data = data[1:23]\n",
    "        dataset.append((x_data, y_data))\n",
    "\n",
    "    X = np.array([x for x, y in dataset])\n",
    "    Y = np.array([y for x, y in dataset])\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "#print tree\n",
    "def print_tree(node, level=0):\n",
    "    if node.attribute_index != None: \n",
    "        print(\"  \" * level, node.attribute_index)\n",
    "        for child in node.children:\n",
    "            print_tree(child, level + 1)\n",
    "    else:\n",
    "        print(\"  \" * level, node.class_value)\n",
    "\n",
    "#prediction \n",
    "def prediction(node, x): \n",
    "    class_label = None\n",
    "\n",
    "    #decision node\n",
    "    if node.attribute_index != None: \n",
    "        index = node.attribute_index\n",
    "        for child in node.children:\n",
    "            if x[index] == child.value_path: \n",
    "                class_label = prediction(child, x)\n",
    "                break\n",
    "    #leaf node\n",
    "    else:\n",
    "        class_label = node.class_value\n",
    "\n",
    "    return class_label\n",
    "\n",
    "\n",
    "#main(): \n",
    "#train data\n",
    "train_X, train_Y = read_data(\"data/mush_train.data\")\n",
    "\n",
    "#create decision tree using training data\n",
    "training_tree = DecisionTree()\n",
    "tree = training_tree.create_decision_tree(train_X, train_Y, None, 0)\n",
    "\n",
    "#print tree\n",
    "print()\n",
    "print(\"Decision tree:\")\n",
    "print_tree(tree)\n",
    "\n",
    "#test data\n",
    "X, Y = read_data(\"data/mush_test.data\")\n",
    "correct_predictions = 0\n",
    "\n",
    "#compute accuracy \n",
    "for x, y in zip(X, Y): \n",
    "    class_label = prediction(tree, x)\n",
    "\n",
    "    if class_label == y: #correct classification\n",
    "        correct_predictions += 1\n",
    "    \n",
    "accuracy = (correct_predictions / X.shape[0]) * 100\n",
    "print(\"\\naccuracy:\", accuracy, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
