{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the result of PCA to select s features \n",
    "Train the model using only selected features using SVM with slack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Paths:  \n",
    "- training data: data/gisette_train.data\n",
    "- validation data: data/gisette_valid.data\n",
    "- test data: data/gisette_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/random.py:510: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  if not _isfinite(total):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 10\n",
      "s 10\n",
      "avg error: 0.28659999999999997\n",
      "\n",
      "k: 10\n",
      "s 20\n",
      "avg error: 0.2072\n",
      "\n",
      "k: 10\n",
      "s 30\n",
      "avg error: 0.1824\n",
      "\n",
      "k: 10\n",
      "s 40\n",
      "avg error: 0.19780000000000003\n",
      "\n",
      "k: 10\n",
      "s 50\n",
      "avg error: 0.14920000000000005\n",
      "\n",
      "k: 10\n",
      "s 60\n",
      "avg error: 0.1418\n",
      "\n",
      "k: 10\n",
      "s 70\n",
      "avg error: 0.11679999999999997\n",
      "\n",
      "k: 10\n",
      "s 80\n",
      "avg error: 0.11779999999999999\n",
      "\n",
      "k: 10\n",
      "s 90\n",
      "avg error: 0.10559999999999999\n",
      "\n",
      "k: 10\n",
      "s 100\n",
      "avg error: 0.09939999999999997\n",
      "\n",
      "k: 20\n",
      "s 10\n",
      "avg error: 0.2840000000000001\n",
      "\n",
      "k: 20\n",
      "s 20\n",
      "avg error: 0.23000000000000004\n",
      "\n",
      "k: 20\n",
      "s 30\n",
      "avg error: 0.19679999999999997\n",
      "\n",
      "k: 20\n",
      "s 40\n",
      "avg error: 0.16320000000000004\n",
      "\n",
      "k: 20\n",
      "s 50\n",
      "avg error: 0.14560000000000003\n",
      "\n",
      "k: 20\n",
      "s 60\n",
      "avg error: 0.13540000000000002\n",
      "\n",
      "k: 20\n",
      "s 70\n",
      "avg error: 0.127\n",
      "\n",
      "k: 20\n",
      "s 80\n",
      "avg error: 0.11279999999999997\n",
      "\n",
      "k: 20\n",
      "s 90\n",
      "avg error: 0.1116\n",
      "\n",
      "k: 20\n",
      "s 100\n",
      "avg error: 0.10619999999999999\n",
      "\n",
      "k: 30\n",
      "s 10\n",
      "avg error: 0.2948\n",
      "\n",
      "k: 30\n",
      "s 20\n",
      "avg error: 0.22920000000000001\n",
      "\n",
      "k: 30\n",
      "s 30\n",
      "avg error: 0.20939999999999995\n",
      "\n",
      "k: 30\n",
      "s 40\n",
      "avg error: 0.17260000000000003\n",
      "\n",
      "k: 30\n",
      "s 50\n",
      "avg error: 0.1688\n",
      "\n",
      "k: 30\n",
      "s 60\n",
      "avg error: 0.12999999999999998\n",
      "\n",
      "k: 30\n",
      "s 70\n",
      "avg error: 0.12599999999999997\n",
      "\n",
      "k: 30\n",
      "s 80\n",
      "avg error: 0.1632\n",
      "\n",
      "k: 30\n",
      "s 90\n",
      "avg error: 0.09899999999999998\n",
      "\n",
      "k: 30\n",
      "s 100\n",
      "avg error: 0.10659999999999999\n",
      "\n",
      "k: 40\n",
      "s 10\n",
      "avg error: 0.3228\n",
      "\n",
      "k: 40\n",
      "s 20\n",
      "avg error: 0.25139999999999996\n",
      "\n",
      "k: 40\n",
      "s 30\n",
      "avg error: 0.18580000000000002\n",
      "\n",
      "k: 40\n",
      "s 40\n",
      "avg error: 0.17760000000000004\n",
      "\n",
      "k: 40\n",
      "s 50\n",
      "avg error: 0.1588\n",
      "\n",
      "k: 40\n",
      "s 60\n",
      "avg error: 0.14540000000000003\n",
      "\n",
      "k: 40\n",
      "s 70\n",
      "avg error: 0.12200000000000003\n",
      "\n",
      "k: 40\n",
      "s 80\n",
      "avg error: 0.15639999999999996\n",
      "\n",
      "k: 40\n",
      "s 90\n",
      "avg error: 0.11560000000000001\n",
      "\n",
      "k: 40\n",
      "s 100\n",
      "avg error: 0.10619999999999999\n",
      "\n",
      "k: 50\n",
      "s 10\n",
      "avg error: 0.29979999999999996\n",
      "\n",
      "k: 50\n",
      "s 20\n",
      "avg error: 0.21899999999999994\n",
      "\n",
      "k: 50\n",
      "s 30\n",
      "avg error: 0.2004\n",
      "\n",
      "k: 50\n",
      "s 40\n",
      "avg error: 0.182\n",
      "\n",
      "k: 50\n",
      "s 50\n",
      "avg error: 0.1738\n",
      "\n",
      "k: 50\n",
      "s 60\n",
      "avg error: 0.1376\n",
      "\n",
      "k: 50\n",
      "s 70\n",
      "avg error: 0.1386\n",
      "\n",
      "k: 50\n",
      "s 80\n",
      "avg error: 0.1206\n",
      "\n",
      "k: 50\n",
      "s 90\n",
      "avg error: 0.15599999999999997\n",
      "\n",
      "k: 50\n",
      "s 100\n",
      "avg error: 0.1436\n",
      "\n",
      "k: 60\n",
      "s 10\n",
      "avg error: 0.29979999999999996\n",
      "\n",
      "k: 60\n",
      "s 20\n",
      "avg error: 0.27899999999999997\n",
      "\n",
      "k: 60\n",
      "s 30\n",
      "avg error: 0.1968\n",
      "\n",
      "k: 60\n",
      "s 40\n",
      "avg error: 0.1688\n",
      "\n",
      "k: 60\n",
      "s 50\n",
      "avg error: 0.166\n",
      "\n",
      "k: 60\n",
      "s 60\n",
      "avg error: 0.14740000000000003\n",
      "\n",
      "k: 60\n",
      "s 70\n",
      "avg error: 0.15899999999999997\n",
      "\n",
      "k: 60\n",
      "s 80\n",
      "avg error: 0.1206\n",
      "\n",
      "k: 60\n",
      "s 90\n",
      "avg error: 0.10659999999999999\n",
      "\n",
      "k: 60\n",
      "s 100\n",
      "avg error: 0.09719999999999998\n",
      "\n",
      "k: 70\n",
      "s 10\n",
      "avg error: 0.3508\n",
      "\n",
      "k: 70\n",
      "s 20\n",
      "avg error: 0.2576\n",
      "\n",
      "k: 70\n",
      "s 30\n",
      "avg error: 0.2098\n",
      "\n",
      "k: 70\n",
      "s 40\n",
      "avg error: 0.1768\n",
      "\n",
      "k: 70\n",
      "s 50\n",
      "avg error: 0.17079999999999998\n",
      "\n",
      "k: 70\n",
      "s 60\n",
      "avg error: 0.1416\n",
      "\n",
      "k: 70\n",
      "s 70\n",
      "avg error: 0.14300000000000002\n",
      "\n",
      "k: 70\n",
      "s 80\n",
      "avg error: 0.203\n",
      "\n",
      "k: 70\n",
      "s 90\n",
      "avg error: 0.11280000000000001\n",
      "\n",
      "k: 70\n",
      "s 100\n",
      "avg error: 0.11639999999999998\n",
      "\n",
      "k: 80\n",
      "s 10\n",
      "avg error: 0.3106\n",
      "\n",
      "k: 80\n",
      "s 20\n",
      "avg error: 0.2716\n",
      "\n",
      "k: 80\n",
      "s 30\n",
      "avg error: 0.21739999999999995\n",
      "\n",
      "k: 80\n",
      "s 40\n",
      "avg error: 0.18120000000000003\n",
      "\n",
      "k: 80\n",
      "s 50\n",
      "avg error: 0.15600000000000006\n",
      "\n",
      "k: 80\n",
      "s 60\n",
      "avg error: 0.21340000000000003\n",
      "\n",
      "k: 80\n",
      "s 70\n",
      "avg error: 0.1476\n",
      "\n",
      "k: 80\n",
      "s 80\n",
      "avg error: 0.11839999999999998\n",
      "\n",
      "k: 80\n",
      "s 90\n",
      "avg error: 0.11599999999999996\n",
      "\n",
      "k: 80\n",
      "s 100\n",
      "avg error: 0.11040000000000001\n",
      "\n",
      "k: 90\n",
      "s 10\n",
      "avg error: 0.33859999999999996\n",
      "\n",
      "k: 90\n",
      "s 20\n",
      "avg error: 0.277\n",
      "\n",
      "k: 90\n",
      "s 30\n",
      "avg error: 0.2002\n",
      "\n",
      "k: 90\n",
      "s 40\n",
      "avg error: 0.18540000000000004\n",
      "\n",
      "k: 90\n",
      "s 50\n",
      "avg error: 0.1882\n",
      "\n",
      "k: 90\n",
      "s 60\n",
      "avg error: 0.154\n",
      "\n",
      "k: 90\n",
      "s 70\n",
      "avg error: 0.1356\n",
      "\n",
      "k: 90\n",
      "s 80\n",
      "avg error: 0.1682\n",
      "\n",
      "k: 90\n",
      "s 90\n",
      "avg error: 0.1608\n",
      "\n",
      "k: 90\n",
      "s 100\n",
      "avg error: 0.12179999999999999\n",
      "\n",
      "k: 100\n",
      "s 10\n",
      "avg error: 0.3422\n",
      "\n",
      "k: 100\n",
      "s 20\n",
      "avg error: 0.274\n",
      "\n",
      "k: 100\n",
      "s 30\n",
      "avg error: 0.22559999999999994\n",
      "\n",
      "k: 100\n",
      "s 40\n",
      "avg error: 0.1822\n",
      "\n",
      "k: 100\n",
      "s 50\n",
      "avg error: 0.1746\n",
      "\n",
      "k: 100\n",
      "s 60\n",
      "avg error: 0.1528\n",
      "\n",
      "k: 100\n",
      "s 70\n",
      "avg error: 0.18320000000000003\n",
      "\n",
      "k: 100\n",
      "s 80\n",
      "avg error: 0.14040000000000002\n",
      "\n",
      "k: 100\n",
      "s 90\n",
      "avg error: 0.11779999999999999\n",
      "\n",
      "k: 100\n",
      "s 100\n",
      "avg error: 0.11379999999999998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import random\n",
    "\n",
    "#read file and store data to X and Y \n",
    "def read_data(filename): \n",
    "    file = open(filename, 'r', encoding='utf-8-sig')\n",
    "    dataset = []\n",
    "    for line in file:\n",
    "        data = line.split(',')\n",
    "        y_data = int(data[0])\n",
    "        x_data = [float(x) for x in data[1:]] \n",
    "        dataset.append((x_data, y_data))\n",
    "\n",
    "    X = np.array([x for x, y in dataset])\n",
    "    Y = np.array([y for x, y in dataset])\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "#training model for the train_data and get an optimal w and b\n",
    "def train(c, X, Y): \n",
    "    num_of_data, num_of_features = X.shape\n",
    "\n",
    "    #P matrix (identity matrix of w's, 0 for b and slack)\n",
    "    P_matrix = np.identity(num_of_features) #identity matrix\n",
    "    P_matrix = np.pad(P_matrix, ((0, 2), (0, 0)), mode='constant', constant_values=0) #add 2 new rows of 0's to the end\n",
    "    P_matrix = np.pad(P_matrix, ((0, 0), (0, 2)), mode='constant', constant_values=0) #add 2 new cols of 0's to the end \n",
    "\n",
    "    #q vector (0's for w's and b, c for slack)\n",
    "    q_vector = np.zeros(num_of_features+1) #col of 0's\n",
    "    q_vector = np.append(q_vector, c) #add c value \n",
    "\n",
    "    #G matrix \n",
    "    Y = Y.reshape(Y.shape[0],1) \n",
    "    G_matrix = -np.multiply(Y, X) #-yixi\n",
    "    bcol = np.array([-y for y in Y]) #-yi\n",
    "    G_matrix = np.hstack((G_matrix, bcol)) #add bcol to G matrix\n",
    "    G_matrix = np.pad(G_matrix, ((0, num_of_data), (0, 0)), mode='constant', constant_values=0) #add 3000 new rows of 0's to the end (for second equality)\n",
    "    scol = -np.ones(num_of_data*2).reshape(num_of_data*2, 1) #col of slack variable (-1)\n",
    "    G_matrix = np.hstack((G_matrix, scol)) #add bcol to G matrix\n",
    "\n",
    "    #h vector\n",
    "    h_vector = -np.ones(num_of_data) #col of -1's\n",
    "    new_col = np.zeros(num_of_data) #col of 0's\n",
    "    h_vector = np.append(h_vector, new_col)\n",
    "\n",
    "    P = cvxopt.matrix(P_matrix)\n",
    "    q = cvxopt.matrix(q_vector)\n",
    "    G = cvxopt.matrix(G_matrix)\n",
    "    h = cvxopt.matrix(h_vector) \n",
    "\n",
    "    cvxopt.solvers.options['show_progress'] = False #disable progess to console \n",
    "    sol = cvxopt.solvers.qp(P, q, G, h) \n",
    "    sol_arr = np.array(sol['x'])\n",
    "\n",
    "    w = sol_arr[:num_of_features]\n",
    "    b = sol_arr[num_of_features]\n",
    "\n",
    "    return w, b\n",
    "\n",
    "#constuct matrix W\n",
    "def construct_W(X): \n",
    "    #get transpose of X (column becomes the data point)\n",
    "    trans_X = X.T\n",
    "    num_data = trans_X.shape[1]\n",
    "\n",
    "    #compute sum of all data points \n",
    "    sum = 0\n",
    "    for j in range(num_data): \n",
    "        sum += trans_X[:, j]\n",
    "    #compute mean\n",
    "    mean = sum / num_data\n",
    "\n",
    "    W = np.zeros(trans_X.shape)\n",
    "    for i in range(num_data): \n",
    "        W[:, i] = trans_X[:, i] - mean\n",
    "    \n",
    "    return W\n",
    "\n",
    "#compute pi\n",
    "def compute_pi(k_eigenvectors): \n",
    "    num_feature, k = k_eigenvectors.shape\n",
    "    pi = []\n",
    "    for j in range(num_feature): \n",
    "        sum = 0\n",
    "        for i in range(k): \n",
    "            sum += k_eigenvectors[j][i] * k_eigenvectors[j][i]\n",
    "        pi_j = 1/k * sum\n",
    "        pi.append(pi_j)\n",
    "    return np.array(pi)\n",
    "\n",
    "#training dataset\n",
    "train_X, train_Y = read_data('data/gisette_train.data')\n",
    "#test dataset\n",
    "X, Y = read_data(\"data/gisette_test.data\")\n",
    "\n",
    "#mean-centering the data\n",
    "means = np.mean(train_X, axis=0)\n",
    "mean_centered_train_X = train_X - means\n",
    "\n",
    "means = np.mean(X, axis=0)\n",
    "mean_centered_X = X - means\n",
    "\n",
    "#construct W\n",
    "W = construct_W(mean_centered_train_X)\n",
    "covariance_matrix = np.dot(W, W.T)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "#sort eigenvalues/eigenvectors in decreasing order\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices] #reorder the columns\n",
    "\n",
    "K = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "S = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "C = [1e6]\n",
    "\n",
    "#select s features with each k\n",
    "for k in K: \n",
    "    #get first k eigenvectors \n",
    "    k_eigenvectors = eigenvectors[:, :k]\n",
    "    pi = compute_pi(k_eigenvectors)\n",
    "\n",
    "    for s in S: \n",
    "        errors = []\n",
    "        for _ in range(10): \n",
    "\n",
    "            #select s features randomly using pi as weight for each feature\n",
    "            selected_features = random.choices(range(len(pi)), pi, k=s)\n",
    "            selected_train_x = mean_centered_train_X[:, selected_features]\n",
    "            selected_x = mean_centered_X[:, selected_features]\n",
    "        \n",
    "            #train model \n",
    "            for c in C: \n",
    "                w, b = train(c, selected_train_x, train_Y)  \n",
    "                correct_predictions = 0\n",
    "                total_data = selected_x.shape[0]\n",
    "\n",
    "                for x, y in zip(selected_x, Y):\n",
    "                    result = y * (np.dot(w.reshape(1, w.shape[0]),x) + b)\n",
    "                    if (result > 0): #correct classification \n",
    "                        correct_predictions += 1\n",
    "                        \n",
    "                accuracy = correct_predictions / total_data\n",
    "                errors.append(1 - accuracy)\n",
    "                \n",
    "                # print(\"c:\", c)\n",
    "                # print(\"accuracy:\", accuracy, \"%\")\n",
    "        print('k:', k)\n",
    "        print('s', s)\n",
    "        print('avg error:', np.mean(errors))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
