{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA to get linear combination of original features.\n",
    "Then train the model with SVM with slack/gaussian kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File Paths:  \n",
    "- training data: data/gisette_train.data\n",
    "- validation data: data/gisette_valid.data\n",
    "- test data: data/gisette_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2695 1761 1320 1051  855]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ruoxian/Downloads/PCA/PCA.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m correct_predictions \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m total_data \u001b[39m=\u001b[39m projected_x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m sv_indices, sv_lagrange_multiplier, support_vectors, sv_y, K_matrix \u001b[39m=\u001b[39m train(c, s, projected_train_x, train_Y)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m sv_y \u001b[39m=\u001b[39m sv_y\u001b[39m.\u001b[39mreshape(sv_y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m \u001b[39m#compute b\u001b[39;00m\n",
      "\u001b[1;32m/Users/ruoxian/Downloads/PCA/PCA.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_of_data): \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_of_data):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         K_matrix[i, j] \u001b[39m=\u001b[39m g_kernel(X[i], X[j], s)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m#P_matrix\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m P_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mouter(Y, Y) \u001b[39m*\u001b[39m K_matrix\n",
      "\u001b[1;32m/Users/ruoxian/Downloads/PCA/PCA.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mg_kernel\u001b[39m(x, z, s): \n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ruoxian/Downloads/PCA/PCA.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(x\u001b[39m-\u001b[39;49mz)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m/\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m(s\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/linalg/linalg.py:2553\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2551\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2552\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mdot(x)\n\u001b[0;32m-> 2553\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2554\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n\u001b[1;32m   2555\u001b[0m     ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mreshape(ndim\u001b[39m*\u001b[39m[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "\n",
    "#read file and store data to X and Y \n",
    "def read_data(filename): \n",
    "    file = open(filename, 'r', encoding='utf-8-sig')\n",
    "    dataset = []\n",
    "    for line in file:\n",
    "        data = line.split(',')\n",
    "        y_data = int(data[0])\n",
    "        x_data = [float(x) for x in data[1:]] \n",
    "        dataset.append((x_data, y_data))\n",
    "\n",
    "    X = np.array([x for x, y in dataset])\n",
    "    Y = np.array([y for x, y in dataset])\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "#gaussian kernel equation k(x, z)\n",
    "def g_kernel(x, z, s): \n",
    "    return np.exp(-np.linalg.norm(x-z)**2/(2*(s**2)))\n",
    "\n",
    "#train data to get optimal lagrange multiplier\n",
    "def train(c, s, X, Y): \n",
    "    num_of_data, _ = X.shape\n",
    "\n",
    "    #Gaussian Matrix\n",
    "    K_matrix = np.zeros((num_of_data, num_of_data))\n",
    "    for i in range(num_of_data): \n",
    "        for j in range(num_of_data):\n",
    "            K_matrix[i, j] = g_kernel(X[i], X[j], s)\n",
    "\n",
    "    #P_matrix\n",
    "    P_matrix = np.outer(Y, Y) * K_matrix\n",
    "\n",
    "    #q_vector\n",
    "    q_vector = -np.ones(num_of_data)\n",
    "\n",
    "    #G_matrix\n",
    "    G_matrix = np.identity(num_of_data)\n",
    "    G_matrix = np.vstack((G_matrix, -np.identity(num_of_data)))\n",
    "\n",
    "    #h_vector\n",
    "    h_vector = np.ones(num_of_data) * c\n",
    "    h_vector = np.hstack((h_vector, np.zeros(num_of_data)))\n",
    "\n",
    "    P = cvxopt.matrix(P_matrix)\n",
    "    q = cvxopt.matrix(q_vector)\n",
    "    G = cvxopt.matrix(G_matrix)\n",
    "    h = cvxopt.matrix(h_vector) \n",
    "    A = cvxopt.matrix(Y.reshape(1, num_of_data) * 1.) \n",
    "    b = cvxopt.matrix(0.0) \n",
    "\n",
    "    cvxopt.solvers.options['show_progress'] = False #disable progess to console \n",
    "    sol = cvxopt.solvers.qp(P, q, G, h, A, b) \n",
    "    lagrange_multiplier = np.array(sol['x'])\n",
    "    \n",
    "    #get support vectors \n",
    "    sv_indices = np.where(lagrange_multiplier > 1e-5)[0]\n",
    "    sv_lagrange_multiplier = lagrange_multiplier[sv_indices]\n",
    "    support_vectors = X[sv_indices]\n",
    "    sv_y = Y[sv_indices]\n",
    "\n",
    "    return sv_indices, sv_lagrange_multiplier, support_vectors, sv_y, K_matrix\n",
    "\n",
    "#constuct matrix W\n",
    "def construct_W(X): \n",
    "    #get transpose of X (column becomes the data point)\n",
    "    trans_X = X.T\n",
    "    num_data = trans_X.shape[1]\n",
    "\n",
    "    #compute sum of all data points \n",
    "    sum = 0\n",
    "    for j in range(num_data): \n",
    "        sum += trans_X[:, j]\n",
    "    #compute mean\n",
    "    mean = sum / num_data\n",
    "\n",
    "    W = np.zeros(trans_X.shape)\n",
    "    for i in range(num_data): \n",
    "        W[:, i] = trans_X[:, i] - mean\n",
    "    \n",
    "    return W\n",
    "\n",
    "#compute smallest k for a given percentage \n",
    "def compute_smallest_k(scaled_eigenvalues, percentage): \n",
    "    k_sum = 0\n",
    "    k = 0\n",
    "\n",
    "    while (k_sum < percentage): \n",
    "        k_sum += scaled_eigenvalues[k]\n",
    "        k += 1\n",
    "\n",
    "    return k\n",
    "\n",
    "#compute K\n",
    "def compute_K(eigenvalues): \n",
    "    K = []\n",
    "    #sum all eigenvalues\n",
    "    sum = np.sum(eigenvalues)\n",
    "    #divide each by the sum\n",
    "    scaled_eigenvalues = eigenvalues / sum\n",
    "    \n",
    "    #k99\n",
    "    k = compute_smallest_k(scaled_eigenvalues, 0.99)\n",
    "    K.append(k)\n",
    "\n",
    "    #k95\n",
    "    k = compute_smallest_k(scaled_eigenvalues, 0.95)\n",
    "    K.append(k)\n",
    "\n",
    "    #k90\n",
    "    k = compute_smallest_k(scaled_eigenvalues, 0.90)\n",
    "    K.append(k)\n",
    "\n",
    "    #k85\n",
    "    k = compute_smallest_k(scaled_eigenvalues, 0.85)\n",
    "    K.append(k)\n",
    "\n",
    "    #k80\n",
    "    k = compute_smallest_k(scaled_eigenvalues, 0.80)\n",
    "    K.append(k)\n",
    "\n",
    "    return np.array(K)\n",
    "\n",
    "#main: \n",
    "#training dataset\n",
    "train_X, train_Y = read_data('data/gisette_train.data')\n",
    "#test dataset\n",
    "X, Y = read_data(\"data/gisette_test.data\")\n",
    "\n",
    "#mean-centering the data\n",
    "means = np.mean(train_X, axis=0)\n",
    "mean_centered_train_X = train_X - means\n",
    "\n",
    "means = np.mean(X, axis=0)\n",
    "mean_centered_X = X - means\n",
    "\n",
    "#PCA\n",
    "W = construct_W(mean_centered_train_X)\n",
    "covariance_matrix = np.dot(W, W.T)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "#sort eigenvalues/eigenvectors in decreasing order\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices] #reorder the columns\n",
    "\n",
    "K = compute_K(eigenvalues)\n",
    "C = [1e6]\n",
    "sigma = [1e4]  \n",
    "\n",
    "#compute k-dimensional subspace for each k\n",
    "for k in K: \n",
    "    #get first k eigenvectors \n",
    "    k_eigenvectors = eigenvectors[:, :k]\n",
    "    projected_train_x = np.dot(mean_centered_train_X, k_eigenvectors)\n",
    "    projected_x = np.dot(mean_centered_X, k_eigenvectors)\n",
    "\n",
    "    for c in C: \n",
    "        for s in sigma: \n",
    "            correct_predictions = 0\n",
    "            total_data = projected_x.shape[0]\n",
    "            sv_indices, sv_lagrange_multiplier, support_vectors, sv_y, K_matrix = train(c, s, projected_train_x, train_Y)\n",
    "            sv_y = sv_y.reshape(sv_y.shape[0], 1)\n",
    "\n",
    "            #compute b\n",
    "            b = 0.0\n",
    "            for i in range(len(sv_indices)):\n",
    "                b += sv_y[i] \n",
    "                b -= np.sum(sv_lagrange_multiplier * sv_y * K_matrix[sv_indices, :][i])\n",
    "            b /= len(sv_indices)\n",
    "\n",
    "            #prediction\n",
    "            for x, y in zip(projected_x, Y):\n",
    "                sum = 0\n",
    "                for i in range(len(sv_indices)):\n",
    "                    sum += sv_lagrange_multiplier[i] * sv_y[i] * g_kernel(support_vectors[i], x, s)\n",
    "                f_x = sum + b\n",
    "        \n",
    "                result = y * f_x\n",
    "                if (result > 0): #correct classification \n",
    "                    correct_predictions += 1\n",
    "                \n",
    "            accuracy = (correct_predictions / total_data) * 100\n",
    "            print('k:', k)\n",
    "            print(\"c:\", c)\n",
    "            print(\"sigma:\", s)\n",
    "            print(\"accuracy:\", accuracy, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
