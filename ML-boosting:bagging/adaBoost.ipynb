{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using the adaBoost algorithm: \n",
    "1. initialized weight as 1/M\n",
    "2. select classifier with least error\n",
    "3. compute alpha\n",
    "4. update weight\n",
    "5. repeat 2-4 for a fixed number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Paths:  \n",
    "- training data: data/heart_train.data\n",
    "- test data: data/heart_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 69.5187165775401 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Decision Stump class (decision tree with single attribute split)\n",
    "class DecisionStump: \n",
    "    def __init__(self): \n",
    "        self.attribute_index = None\n",
    "        self.polarity = None    #left: -1 or left: 1 for label\n",
    "        self.threshold = None   #< 1 or < -1\n",
    "        self.alpha = None\n",
    "    \n",
    "    #get pred_Y for decision stump \n",
    "    def predict(self, X): \n",
    "        attribute_set = X[:, self.attribute_index]\n",
    "        pred_Y = np.zeros(len(attribute_set))\n",
    "        \n",
    "        for i in range(len(attribute_set)): \n",
    "            if self.polarity == -1: \n",
    "                if attribute_set[i] < self.threshold: \n",
    "                    pred_Y[i] = -1\n",
    "                else: \n",
    "                    pred_Y[i] = 1\n",
    "            else:   \n",
    "                if attribute_set[i] < self.threshold: \n",
    "                    pred_Y[i] = 1\n",
    "                else: \n",
    "                    pred_Y[i] = -1\n",
    "\n",
    "        return pred_Y\n",
    "\n",
    "\n",
    "#AdaBoost algorithm class\n",
    "class AdaBoost: \n",
    "    def __init__(self, rounds=10): \n",
    "        self.rounds = rounds\n",
    "        self.all_classifiers = []\n",
    "\n",
    "    #training of model using AdaBoost algorithm\n",
    "    def train(self, X, Y):\n",
    "        num_data, num_attributes = X.shape\n",
    "\n",
    "        #initialize data weights as 1/M\n",
    "        data_weights = np.ones(num_data) * (1 / num_data)\n",
    "\n",
    "        #compute weak_classifiers for t rounds\n",
    "        for _ in range(self.rounds): \n",
    "            classifier = DecisionStump()\n",
    "            min_error = float('inf')\n",
    "\n",
    "            #iterate through each attributes to select the classifier with least error \n",
    "            for i in range(num_attributes):\n",
    "                attribute_set = X[:, i]\n",
    "                thresholds = [-1, 1]\n",
    "                polarity = [-1, 1]\n",
    "\n",
    "                #try every possible classification for each attribute \n",
    "                for p in polarity:\n",
    "                    for t in thresholds: \n",
    "                        pred_Y = self.predict(attribute_set, t, p)\n",
    "\n",
    "                        #compute error\n",
    "                        error = 0\n",
    "                        for j in range(num_data): \n",
    "                            if Y[j] != pred_Y[j]:\n",
    "                                error += data_weights[j]\n",
    "\n",
    "                        #get classifier with least error \n",
    "                        if error < min_error: \n",
    "                            min_error = error\n",
    "                            classifier.attribute_index = i\n",
    "                            classifier.polarity = p\n",
    "                            classifier.threshold = t\n",
    "            \n",
    "            #compute alpha\n",
    "            classifier.alpha = 1/2 * np.log((1 - min_error) / min_error)\n",
    "\n",
    "            #get pred_Y on the selected classifier\n",
    "            pred_Y = classifier.predict(X)\n",
    "\n",
    "            #update data weights\n",
    "            data_weights = (data_weights * np.exp(-Y * pred_Y * classifier.alpha)) / (2 * np.sqrt(min_error * (1 - min_error)))\n",
    "            \n",
    "            #append classifer to list\n",
    "            self.all_classifiers.append(classifier)\n",
    "    \n",
    "    #prediction of weak classifier \n",
    "    def predict(self, attribute_set, t, p): \n",
    "        pred_Y = np.zeros(len(attribute_set))\n",
    "        \n",
    "        for i in range(len(attribute_set)): \n",
    "            if p == -1: \n",
    "                if attribute_set[i] < t: \n",
    "                    pred_Y[i] = -1\n",
    "                else: \n",
    "                    pred_Y[i] = 1\n",
    "            else:   \n",
    "                if attribute_set[i] < t: \n",
    "                    pred_Y[i] = 1\n",
    "                else: \n",
    "                    pred_Y[i] = -1\n",
    "\n",
    "        return pred_Y\n",
    "\n",
    "    #final prediction \n",
    "    def final_predict(self, X): \n",
    "        sum = 0\n",
    "        for t in range(self.rounds):\n",
    "            sum += self.all_classifiers[t].alpha * self.all_classifiers[t].predict(X)\n",
    "        return np.sign(sum)\n",
    "\n",
    "\n",
    "#read file and store data to X and Y \n",
    "def read_data(filename): \n",
    "    file = open(filename, 'r', encoding='utf-8-sig')\n",
    "    dataset = []\n",
    "    for line in file:\n",
    "        data = line.split(',')\n",
    "        y_data = int(data[0]) \n",
    "        x_data = [float(x) for x in data[1:23]] \n",
    "        dataset.append((x_data, y_data))\n",
    "\n",
    "    X = np.array([x for x, y in dataset])\n",
    "    Y = np.array([y for x, y in dataset])\n",
    "    #replace 0 with -1\n",
    "    X = np.where(X == 0, -1, X)\n",
    "    Y = np.where(Y == 0, -1, Y) \n",
    "\n",
    "    return X, Y\n",
    "\n",
    "#compute accuracy \n",
    "def compute_accuracy(Y, pred_Y): \n",
    "    correct_predictions = 0\n",
    "\n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i] == pred_Y[i]: \n",
    "            correct_predictions += 1\n",
    "    return (correct_predictions / Y.shape[0]) * 100\n",
    "\n",
    "\n",
    "#train dataset\n",
    "train_X, train_Y = read_data('data/heart_train.data')\n",
    "#test dataset\n",
    "X, Y = read_data('data/heart_test.data')\n",
    "\n",
    "#get final classifier\n",
    "final_classifier = AdaBoost(rounds=10)\n",
    "final_classifier.train(train_X, train_Y)\n",
    "\n",
    "#get final prediction\n",
    "pred_Y = final_classifier.final_predict(X)\n",
    "\n",
    "#compute accuracy \n",
    "accuracy = compute_accuracy(Y, pred_Y)\n",
    "print('accuracy:', accuracy, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
