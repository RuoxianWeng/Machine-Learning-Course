{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using Bagging algorithm: \n",
    "1. generate n bootstrap samples from original dataset\n",
    "2. train each sample by finding the classifier with most info gain \n",
    "3. get prediction for each classifier \n",
    "4. use majority vote in all predictions to predict the unseen datapoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Paths:  \n",
    "- training data: data/heart_train.data\n",
    "- test data: data/heart_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 60.42780748663101 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#read file and store data to X and Y \n",
    "def read_data(filename): \n",
    "    file = open(filename, 'r', encoding='utf-8-sig')\n",
    "    dataset = []\n",
    "    for line in file:\n",
    "        data = line.split(',')\n",
    "        y_data = int(data[0]) \n",
    "        x_data = [float(x) for x in data[1:23]] \n",
    "        dataset.append((x_data, y_data))\n",
    "\n",
    "    X = np.array([x for x, y in dataset])\n",
    "    Y = np.array([y for x, y in dataset])\n",
    "    #replace 0 with -1\n",
    "    X = np.where(X == 0, -1, X)\n",
    "    Y = np.where(Y == 0, -1, Y) \n",
    "\n",
    "    return X, Y\n",
    "\n",
    "#create a new sample of dataset randomly (with replacement)\n",
    "def compute_bootstrap_sample(X, Y): \n",
    "    sample_X = []\n",
    "    sample_Y = []\n",
    "    num_data = X.shape[0]\n",
    "\n",
    "    while len(sample_X) < num_data: \n",
    "        index = random.randrange(num_data)\n",
    "        sample_X.append(X[index])\n",
    "        sample_Y.append(Y[index])\n",
    "\n",
    "    return np.array(sample_X), np.array(sample_Y)\n",
    "\n",
    "#compute entropy\n",
    "def calculate_entropy(label): \n",
    "    classes, class_count = np.unique(label, return_counts=True)\n",
    "    total_count = np.sum(class_count)\n",
    "\n",
    "    entropy_value = 0\n",
    "    for i in range(len(classes)): \n",
    "        proportion = class_count[i] / total_count\n",
    "        entropy_value += (-proportion) * np.log2(proportion)\n",
    "    \n",
    "    return entropy_value\n",
    "\n",
    "#compute conditional entropy\n",
    "def calculate_conditional_entropy(attribute_set, label):\n",
    "    values, value_count = np.unique(attribute_set, return_counts=True)\n",
    "    \n",
    "    total_count = np.sum(value_count)\n",
    "\n",
    "    conditional_entropy_value = 0\n",
    "    #iterate through each value of the attribute\n",
    "    for i in range(len(values)): \n",
    "        condition_set = np.array([label[y] for y in np.where(attribute_set == values[i])])\n",
    "        conditional_entropy_value += (value_count[i] / total_count) * calculate_entropy(condition_set)\n",
    "\n",
    "    return conditional_entropy_value\n",
    "\n",
    "#select the best classifier (most info gain)\n",
    "def select_classifier(X, Y): \n",
    "    max_info_gain = 0\n",
    "    best_attribute_index = 0\n",
    "\n",
    "    current_entropy = calculate_entropy(Y)\n",
    "\n",
    "    #iterate through all attributes to find the one with most information gain \n",
    "    for i in range(X.shape[1]):\n",
    "        attribute_set = X[:, i]\n",
    "        \n",
    "        conditional_entropy = calculate_conditional_entropy(attribute_set, Y)\n",
    "        info_gain = current_entropy - conditional_entropy\n",
    "        \n",
    "        if info_gain >= max_info_gain: \n",
    "            max_info_gain = info_gain\n",
    "            best_attribute_index = i\n",
    "    \n",
    "    return best_attribute_index\n",
    "\n",
    "#prediction of classifier \n",
    "def classifier_prediction(X, Y, attribute_index): \n",
    "    attribute_set = X[:, attribute_index]\n",
    "    pred_Y = np.ones(Y.shape[0])\n",
    "    pred_Y[attribute_set == -1] = -1\n",
    "    return pred_Y\n",
    "\n",
    "#final prediction\n",
    "def final_prediction(predictions, X): \n",
    "    pred_Y = []\n",
    "\n",
    "    #count prediction of each index for each classifier \n",
    "    for prediction in zip(*predictions): \n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        for i in range(len(prediction)): \n",
    "            if prediction[i] == 1: \n",
    "                pos_count += 1\n",
    "            else: \n",
    "                neg_count += 1\n",
    "        if pos_count >= neg_count: \n",
    "            pred_Y.append(1)\n",
    "        else: \n",
    "            pred_Y.append(-1)\n",
    "\n",
    "    return pred_Y\n",
    "            \n",
    "#compute accuracy \n",
    "def compute_accuracy(Y, pred_Y): \n",
    "    correct_predictions = 0\n",
    "\n",
    "    for actual_y, pred_y in zip(Y, pred_Y):\n",
    "        if actual_y == pred_y: \n",
    "            correct_predictions += 1\n",
    "    return (correct_predictions / Y.shape[0]) * 100\n",
    "\n",
    "\n",
    "#train dataset\n",
    "train_X, train_Y = read_data('data/heart_train.data')\n",
    "#test dataset\n",
    "X, Y = read_data('data/heart_test.data')\n",
    "\n",
    "bootstrap_sample_X = []\n",
    "bootstrap_sample_Y = []\n",
    "classifiers = []\n",
    "predictions = []\n",
    "\n",
    "#bagging algorithm\n",
    "for i in range(20): \n",
    "    #create a new bootstrap sample\n",
    "    sample_X, sample_Y = compute_bootstrap_sample(train_X, train_Y)\n",
    "    bootstrap_sample_X.append(sample_X)\n",
    "    bootstrap_sample_Y.append(sample_Y)\n",
    "\n",
    "    #select a classifier \n",
    "    classifier = select_classifier(bootstrap_sample_X[i], bootstrap_sample_Y[i])\n",
    "    classifiers.append(classifier)\n",
    "\n",
    "    #compute prediction on classifier for unseen data\n",
    "    prediction = classifier_prediction(X, Y, classifiers[i])\n",
    "    predictions.append(prediction)\n",
    "\n",
    "#final prediction\n",
    "final_pred_Y = final_prediction(predictions, X)\n",
    "\n",
    "accuracy = compute_accuracy(Y, final_pred_Y)\n",
    "print('accuracy:', accuracy, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
