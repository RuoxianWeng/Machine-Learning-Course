{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using coordinate descent (different initialization and iteration order than adaBoost): \n",
    "1. initialize alpha to any value\n",
    "2. select classifier with least exponential loss\n",
    "3. update alpha\n",
    "4. repeat 2-3 until alpha converges "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Paths:  \n",
    "- training data: data/heart_train.data\n",
    "- test data: data/heart_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "optimal alpha: 0.019582970497356623\n",
      "exponential loss: 43.05095129366278\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Decision Stump class (decision tree with single attribute split)\n",
    "class DecisionStump: \n",
    "    def __init__(self): \n",
    "        self.attribute_index = None\n",
    "        self.polarity = None\n",
    "        self.threshold = None\n",
    "        self.alpha = None\n",
    "    \n",
    "    #get pred_Y for decision stump \n",
    "    def predict(self, X): \n",
    "        attribute_set = X[:, self.attribute_index]\n",
    "        pred_Y = np.zeros(len(attribute_set))\n",
    "        \n",
    "        for i in range(len(attribute_set)): \n",
    "            if self.polarity == -1: \n",
    "                if attribute_set[i] < self.threshold: \n",
    "                    pred_Y[i] = -1\n",
    "                else: \n",
    "                    pred_Y[i] = 1\n",
    "            else:   \n",
    "                if attribute_set[i] < self.threshold: \n",
    "                    pred_Y[i] = 1\n",
    "                else: \n",
    "                    pred_Y[i] = -1\n",
    "        return pred_Y\n",
    "\n",
    "#coordinate descent algorithm\n",
    "class CoordinateDescent: \n",
    "    def __init__(self): \n",
    "        self.all_classifiers = []\n",
    "        self.iterations = 0\n",
    "    \n",
    "    def train(self, X, Y): \n",
    "        num_data, num_attributes = X.shape\n",
    "        #alpha initialization\n",
    "        alpha = 0.5 \n",
    "\n",
    "        while True:\n",
    "            classifier = DecisionStump()\n",
    "            min_loss = float('inf')\n",
    "\n",
    "            #get sum of prediction without new iteration\n",
    "            if self.iterations == 0: \n",
    "                prev_sum_predict = np.zeros(num_data)\n",
    "            else: \n",
    "                prev_sum_predict = self.sum_of_predict(X)\n",
    "\n",
    "            #iterate through all attributes \n",
    "            for i in range(num_attributes): \n",
    "                attribute_set = X[:, i]\n",
    "                thresholds = [-1, 1]\n",
    "                polarity = [-1, 1]\n",
    "\n",
    "                #try every possible classification for each attribute \n",
    "                for p in polarity:\n",
    "                    for t in thresholds: \n",
    "                        #get current prediction \n",
    "                        pred_Y = alpha * self.predict(attribute_set, t, p)\n",
    "                        \n",
    "                        #add current prediction with sum prediction\n",
    "                        cur_sum_predict = prev_sum_predict + pred_Y\n",
    "                        \n",
    "                        #compute exponential loss\n",
    "                        loss = np.sum(np.exp(-Y * cur_sum_predict))\n",
    "                        \n",
    "                        #get classifier with min loss\n",
    "                        if loss < min_loss: \n",
    "                            min_loss = loss\n",
    "                            classifier.attribute_index = i\n",
    "                            classifier.polarity = p\n",
    "                            classifier.threshold = t\n",
    "\n",
    "            #get pred_Y for selected classifier \n",
    "            pred_Y = self.predict(X[:, classifier.attribute_index], classifier.threshold, classifier.polarity)\n",
    "            \n",
    "            #indices where pred_Y == Y\n",
    "            corr_classified_indices = np.where(pred_Y == Y)[0]\n",
    "            #indices where pred_Y != Y\n",
    "            incorr_classified_indices = np.where(pred_Y != Y)[0]\n",
    "\n",
    "            #update alpha\n",
    "            sum_correct = np.sum(np.exp(-Y[corr_classified_indices] * prev_sum_predict[corr_classified_indices]))\n",
    "            sum_incorrect = np.sum(np.exp(-Y[incorr_classified_indices] * prev_sum_predict[incorr_classified_indices]))\n",
    "            alpha = 1/2 * np.log(sum_correct / sum_incorrect)\n",
    "            classifier.alpha = alpha\n",
    "            \n",
    "            # print('index:', classifier.attribute_index)\n",
    "            # print('alpha:', classifier.alpha)\n",
    "            # print('min_loss', min_loss)\n",
    "\n",
    "            #append classifer to list\n",
    "            self.all_classifiers.append(classifier)\n",
    "\n",
    "            #convergence criteria\n",
    "            if self.iterations > 0: \n",
    "                #if alpha is not changing much, exit\n",
    "                if abs(self.all_classifiers[self.iterations].alpha - self.all_classifiers[self.iterations-1].alpha) < 1e-5: \n",
    "                    break\n",
    "\n",
    "            self.iterations += 1\n",
    "        \n",
    "        return alpha, min_loss\n",
    "\n",
    "    #prediction of weak classifier \n",
    "    def predict(self, attribute_set, t, p): \n",
    "        pred_Y = np.zeros(len(attribute_set))\n",
    "        \n",
    "        for i in range(len(attribute_set)): \n",
    "            if p == -1: \n",
    "                if attribute_set[i] < t: \n",
    "                    pred_Y[i] = -1\n",
    "                else: \n",
    "                    pred_Y[i] = 1\n",
    "            else:   \n",
    "                if attribute_set[i] < t: \n",
    "                    pred_Y[i] = 1\n",
    "                else: \n",
    "                    pred_Y[i] = -1\n",
    "\n",
    "        return pred_Y\n",
    "    \n",
    "    #sum of prediction \n",
    "    def sum_of_predict(self, X): \n",
    "        sum = 0\n",
    "        for t in range(self.iterations):\n",
    "            sum += self.all_classifiers[t].alpha * self.all_classifiers[t].predict(X)\n",
    "        return sum\n",
    "    \n",
    "\n",
    "#read file and store data to X and Y \n",
    "def read_data(filename): \n",
    "    file = open(filename, 'r', encoding='utf-8-sig')\n",
    "    dataset = []\n",
    "    for line in file:\n",
    "        data = line.split(',')\n",
    "        y_data = int(data[0]) \n",
    "        x_data = [float(x) for x in data[1:23]] \n",
    "        dataset.append((x_data, y_data))\n",
    "\n",
    "    X = np.array([x for x, y in dataset])\n",
    "    Y = np.array([y for x, y in dataset])\n",
    "    #replace 0 with -1\n",
    "    X = np.where(X == 0, -1, X)\n",
    "    Y = np.where(Y == 0, -1, Y) \n",
    "\n",
    "    return X, Y\n",
    "\n",
    "#train dataset\n",
    "train_X, train_Y = read_data('data/heart_train.data')\n",
    "\n",
    "#train model\n",
    "final_classifier = CoordinateDescent()\n",
    "alpha, loss = final_classifier.train(train_X, train_Y)\n",
    "\n",
    "print('optimal alpha:', alpha)\n",
    "print('exponential loss:', loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
